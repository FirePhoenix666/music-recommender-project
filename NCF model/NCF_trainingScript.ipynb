{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecc0796-f993-4785-befb-f7102e265234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d32f0f2",
   "metadata": {},
   "source": [
    "This is just a script of model training and the codes are repetition from NCF_model hence we will not make any repeated annotation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "220ec832-597e-4b04-b42b-b6962b8b57c9",
   "metadata": {},
   "source": [
    "Load train data which is 80% of the entire playlist and the last column is list of 49 tracks of 0 label tracks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f738725-ced8-4e57-9449-10cd30147f12",
   "metadata": {},
   "source": [
    "Load test data which is 20% of playlist without negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a7ff5e-d763-4117-8dfd-a4f79773afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_label = pd.read_csv(\"trainDF61.csv\", sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276ea4d0-e54e-4b07-9956-d72fcb2fe593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124726</td>\n",
       "      <td>19717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142752</td>\n",
       "      <td>422369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121208</td>\n",
       "      <td>238275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123947</td>\n",
       "      <td>391649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114258</td>\n",
       "      <td>335513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid  track_id  label\n",
       "0  124726     19717      0\n",
       "1  142752    422369      0\n",
       "2  121208    238275      1\n",
       "3  123947    391649      1\n",
       "4  114258    335513      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_with_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107e8f43-f908-4f32-9620-b84c1ca45cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>encoded_track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102489</td>\n",
       "      <td>[215623, 393454, 69228, 4854, 439226, 165886, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10787</td>\n",
       "      <td>[154957, 453219, 104309, 389316, 37543, 158183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135699</td>\n",
       "      <td>[263624, 78766, 68030, 263570, 266054, 190141,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105545</td>\n",
       "      <td>[323172, 426350, 386201, 343344, 294639, 31349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100888</td>\n",
       "      <td>[128887, 75980, 51200, 368949, 233305, 438419,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid                                  encoded_track_uri\n",
       "0  102489  [215623, 393454, 69228, 4854, 439226, 165886, ...\n",
       "1   10787  [154957, 453219, 104309, 389316, 37543, 158183...\n",
       "2  135699  [263624, 78766, 68030, 263570, 266054, 190141,...\n",
       "3  105545  [323172, 426350, 386201, 343344, 294639, 31349...\n",
       "4  100888  [128887, 75980, 51200, 368949, 233305, 438419,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_DF = pd.read_csv(\"testWithoutNegative.csv\", sep='\\t',  encoding='utf-8', index_col =None)\n",
    "test_DF = test_DF.loc[:,['pid', 'encoded_track_uri']]\n",
    "test_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1106cd1-0847-47c1-9807-52f648c70e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>102312</td>\n",
       "      <td>310283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>14157</td>\n",
       "      <td>26349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>113235</td>\n",
       "      <td>312440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>129834</td>\n",
       "      <td>20220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>124700</td>\n",
       "      <td>16483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid track_id  label\n",
       "3938  102312   310283      1\n",
       "2298   14157    26349      1\n",
       "1036  113235   312440      1\n",
       "3630  129834    20220      1\n",
       "1183  124700    16483      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_DF = test_DF.loc[:,['pid','encoded_track_uri']].reset_index(drop=True).rename(columns={'encoded_track_uri': 'track_id'})\n",
    "test_DF['track_id'] = test_DF['track_id'].apply(ast.literal_eval)\n",
    "test_DF = test_DF.explode(\"track_id\")\n",
    "test_DF['label'] = 1\n",
    "test_DF = test_DF.sample(frac=1, random_state=1)\n",
    "test_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d9a03b-0af6-4d56-b990-1dcdda9b7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train = np.array(train_data_with_label['pid'], dtype=int)\n",
    "item_train = np.array(train_data_with_label['track_id'], dtype=int)\n",
    "label_train = np.array(train_data_with_label['label'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7fc3de-dc2b-446d-9ffe-85c76a458084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 13:42:58.908544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:42:59.013497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:42:59.015199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:42:59.021464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 13:42:59.023292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:42:59.024934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:42:59.026489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:43:01.109252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:43:01.111146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:43:01.112727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:43:01.114308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13642 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"user_input\": user_train, \"item_input\": item_train}, label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d73b3b4-0473-4fb6-a733-1d1a8acc7da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = tf.convert_to_tensor(np.array(test_DF['pid'], dtype=int), dtype=tf.int32)\n",
    "test_item = tf.convert_to_tensor(np.array(test_DF['track_id'], dtype=int), dtype=tf.int32)\n",
    "test_tensor = {\"user_input\": test_user, \"item_input\": test_item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29d0213-6ab8-478c-96f6-84999fe10617",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "train_data = tf.data.Dataset.from_tensor_slices(((user_train, item_train), label_train))\n",
    "train_data = train_data.shuffle(buffer_size=1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edaa5014-b5f3-41fd-968b-de1a6c84c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = train_data_with_label.loc[train_data_with_label['label'] == 1, 'pid'].nunique()\n",
    "num_items = train_data_with_label.loc[train_data_with_label['label'] == 1, 'track_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebe334e3-46d5-445f-aa64-d2bf19ed9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, mf_dim=8, layers=[64, 32, 16, 8], reg_layers=[0, 0, 0, 0], reg_mf = [0,0]):\n",
    "    \n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers) #Number of layers in the MLP\n",
    "    # Input variables\n",
    "    user_input = tf.keras.Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = tf.keras.Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "    \n",
    "    # Embedding layer\n",
    "    MF_Embedding_User = tf.keras.layers.Embedding(input_dim = num_users, output_dim = mf_dim, name = 'mf_embedding_user',\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_mf[0]), input_length=1)\n",
    "    MF_Embedding_Item = tf.keras.layers.Embedding(input_dim = num_items, output_dim = mf_dim, name = 'mf_embedding_item',\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_mf[1]), input_length=1)   \n",
    "\n",
    "    MLP_Embedding_User = tf.keras.layers.Embedding(input_dim = num_users, output_dim = int(layers[0]/2), name = \"mlp_embedding_user\",\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_layers[0]), input_length=1)\n",
    "    MLP_Embedding_Item = tf.keras.layers.Embedding(input_dim = num_items, output_dim = int(layers[0]/2), name = 'mlp_embedding_item',\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_layers[0]), input_length=1)   \n",
    "    \n",
    "    # MF part\n",
    "    mf_user_latent = tf.keras.layers.Flatten()(MF_Embedding_User(user_input))\n",
    "    mf_item_latent = tf.keras.layers.Flatten()(MF_Embedding_Item(item_input))\n",
    "    mf_vector = tf.keras.layers.Multiply()([mf_user_latent, mf_item_latent]) # element-wise multiply \n",
    "\n",
    "    # MLP part \n",
    "    mlp_user_latent = tf.keras.layers.Flatten()(MLP_Embedding_User(user_input))\n",
    "    mlp_item_latent = tf.keras.layers.Flatten()(MLP_Embedding_Item(item_input))\n",
    "    mlp_vector = tf.keras.layers.Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = tf.keras.layers.Dense(layers[idx], kernel_regularizer= tf.keras.regularizers.l2(reg_layers[idx]), activation='relu', name=\"layer%d\" %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    # Concatenate MF and MLP parts\n",
    "    #mf_vector = Lambda(lambda x: x * alpha)(mf_vector)\n",
    "    #mlp_vector = Lambda(lambda x : x * (1-alpha))(mlp_vector)\n",
    "    predict_vector = tf.keras.layers.Concatenate()([mf_vector, mlp_vector])\n",
    "    \n",
    "    # Final prediction layer\n",
    "    prediction = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[user_input, item_input], \n",
    "                  outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2cacb984-424a-43b1-80ec-513a44b87655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(num_users, num_items) #default papers model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42226b9b-2067-4f68-b754-f20bba7d4d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_user (Embedding)  (None, 1, 32)        1189472     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_item (Embedding)  (None, 1, 32)        13437376    item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_50 (Flatten)            (None, 32)           0           mlp_embedding_user[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_51 (Flatten)            (None, 32)           0           mlp_embedding_item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 64)           0           flatten_50[0][0]                 \n",
      "                                                                 flatten_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_user (Embedding)   (None, 1, 8)         297368      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_item (Embedding)   (None, 1, 8)         3359344     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 8)            0           mf_embedding_user[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_49 (Flatten)            (None, 8)            0           mf_embedding_item[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 8)            0           flatten_48[0][0]                 \n",
      "                                                                 flatten_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16)           0           multiply_12[0][0]                \n",
      "                                                                 layer3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            17          concatenate_25[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 18,286,321\n",
      "Trainable params: 18,286,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88580b14-993d-46f7-b951-14736a0e2777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 46s 9ms/step - loss: 0.4603 - accuracy: 0.7696\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.3929 - accuracy: 0.8150\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2991 - accuracy: 0.8696\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2383 - accuracy: 0.8984\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.2081 - accuracy: 0.9101\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1870 - accuracy: 0.9176\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1738 - accuracy: 0.9218\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1630 - accuracy: 0.9251\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1593 - accuracy: 0.9260\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1529 - accuracy: 0.9283\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1507 - accuracy: 0.9291\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1480 - accuracy: 0.9297\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1460 - accuracy: 0.9304\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1446 - accuracy: 0.9307\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1422 - accuracy: 0.9317\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1419 - accuracy: 0.9317\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1410 - accuracy: 0.9318\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1402 - accuracy: 0.9321\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1379 - accuracy: 0.9328\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1405 - accuracy: 0.9320\n",
      "CPU times: user 16min 43s, sys: 4min 19s, total: 21min 2s\n",
      "Wall time: 14min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(train_data, epochs=20) #vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8beb7ad8-555c-42e8-baab-91ab381784b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "532336e2-ee30-4296-abbf-8dc3d19f0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/jupyter/model_results/latent_8.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a20c398e-c862-40f9-b9d2-a7459d0ae93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/jupyter/model_results/latent_8.npy', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87254131-6579-44c8-80ff-d19a3dfa31fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.4623 - accuracy: 0.7676\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.3964 - accuracy: 0.8139\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2998 - accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2328 - accuracy: 0.9009\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2003 - accuracy: 0.9140\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.1840 - accuracy: 0.9199\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1699 - accuracy: 0.9237\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1616 - accuracy: 0.9258\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1573 - accuracy: 0.9263\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1546 - accuracy: 0.9267\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1534 - accuracy: 0.9272\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.1527 - accuracy: 0.9273\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1504 - accuracy: 0.9283\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1494 - accuracy: 0.9284\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1478 - accuracy: 0.9289\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.1435 - accuracy: 0.9306\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.1446 - accuracy: 0.9302\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.1440 - accuracy: 0.9303\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.1437 - accuracy: 0.9304\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1422 - accuracy: 0.9310\n",
      "/home/jupyter/model_results/latent_16.pkl -- saved\n",
      "/home/jupyter/model_results/latent_16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 65s 13ms/step - loss: 0.4603 - accuracy: 0.7698\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.3926 - accuracy: 0.8159\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.2908 - accuracy: 0.8730\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.2287 - accuracy: 0.9022\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1974 - accuracy: 0.9144\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1818 - accuracy: 0.9192\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1724 - accuracy: 0.9221\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1613 - accuracy: 0.9258\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1575 - accuracy: 0.9266\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1515 - accuracy: 0.9288\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1486 - accuracy: 0.9296\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1461 - accuracy: 0.9304\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1436 - accuracy: 0.9313\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1415 - accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1405 - accuracy: 0.9323\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1396 - accuracy: 0.9326\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1390 - accuracy: 0.9327\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1382 - accuracy: 0.9330\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1382 - accuracy: 0.9329\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.1356 - accuracy: 0.9340\n",
      "/home/jupyter/model_results/latent_32.pkl -- saved\n",
      "/home/jupyter/model_results/latent_32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.4637 - accuracy: 0.7650\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.3868 - accuracy: 0.8183\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2892 - accuracy: 0.8739\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.2366 - accuracy: 0.8980\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.2102 - accuracy: 0.9086\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1949 - accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1796 - accuracy: 0.9194\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1736 - accuracy: 0.9212\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1693 - accuracy: 0.9221\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1625 - accuracy: 0.9242\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1606 - accuracy: 0.9246\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1552 - accuracy: 0.9265\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1542 - accuracy: 0.9267\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1557 - accuracy: 0.9258\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 94s 19ms/step - loss: 0.1504 - accuracy: 0.9282\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1481 - accuracy: 0.9289\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1444 - accuracy: 0.9303\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1442 - accuracy: 0.9305\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1449 - accuracy: 0.9301\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1437 - accuracy: 0.9305\n",
      "/home/jupyter/model_results/latent_64.pkl -- saved\n",
      "/home/jupyter/model_results/latent_64.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 149s 31ms/step - loss: 0.4622 - accuracy: 0.7677\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.3831 - accuracy: 0.8208\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.2892 - accuracy: 0.8727\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.2332 - accuracy: 0.9008\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 147s 31ms/step - loss: 0.2076 - accuracy: 0.9112\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1873 - accuracy: 0.9183\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1772 - accuracy: 0.9211\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1701 - accuracy: 0.9230\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1610 - accuracy: 0.9258\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1576 - accuracy: 0.9265\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1531 - accuracy: 0.9282\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 147s 31ms/step - loss: 0.1509 - accuracy: 0.9286\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1495 - accuracy: 0.9292\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 147s 31ms/step - loss: 0.1472 - accuracy: 0.9299\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1443 - accuracy: 0.9308\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1441 - accuracy: 0.9306\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1420 - accuracy: 0.9313\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 147s 31ms/step - loss: 0.1413 - accuracy: 0.9317\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1393 - accuracy: 0.9325\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 148s 31ms/step - loss: 0.1409 - accuracy: 0.9318\n",
      "/home/jupyter/model_results/latent_128.pkl -- saved\n",
      "/home/jupyter/model_results/latent_128.npy -- saved\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:442: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 107499008 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4805/4805 [==============================] - 259s 54ms/step - loss: 0.4622 - accuracy: 0.7665\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 258s 54ms/step - loss: 0.3809 - accuracy: 0.8216\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 258s 54ms/step - loss: 0.2832 - accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 258s 54ms/step - loss: 0.2245 - accuracy: 0.9025\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 258s 54ms/step - loss: 0.1978 - accuracy: 0.9133\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 258s 54ms/step - loss: 0.1823 - accuracy: 0.9189\n",
      "Epoch 7/20\n",
      "1919/4805 [==========>...................] - ETA: 2:35 - loss: 0.1731 - accuracy: 0.9217"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2318/1277108320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"latent_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"latent=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "predictions = {}\n",
    "latent_dimension = [16, 32, 64, 128, 256]\n",
    "\n",
    "for i in latent_dimension:\n",
    "    model = get_model(num_users, num_items, i)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    results[\"latent_\" + str(i)] = model.fit(train_data, epochs=20)\n",
    "    predictions[\"latent=\" + str(i)] = model.predict(test_tensor) \n",
    "\n",
    "    spath = \"/home/jupyter/model_results/\" + \"latent_\" +str(i)+\".pkl\"\n",
    "    with open(spath, 'wb') as file:\n",
    "        pickle.dump(results[\"latent_\" + str(i)].history, file)\n",
    "    print(f\"{spath} -- saved\")\n",
    "    \n",
    "    path = \"/home/jupyter/model_results/\" + \"latent_\" +str(i) + \".npy\"\n",
    "    np.save(path, predictions[\"latent=\" + str(i)])\n",
    "    print(f\"{path} -- saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb70aa1-0de5-4ac8-b8ef-9ff535857f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_model(num_users, num_items, mf_dim=8, layers=[64, 32, 16, 8], reg_layers=[0, 0, 0, 0], reg_mf = [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b0e79d8-a205-4461-a509-c3e9eb07c59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.4729 - accuracy: 0.7520\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.4134 - accuracy: 0.7965\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.3800 - accuracy: 0.8209\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.3423 - accuracy: 0.8332\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.3046 - accuracy: 0.8527\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2842 - accuracy: 0.8657\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.2677 - accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2545 - accuracy: 0.8805\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2441 - accuracy: 0.8844\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.2359 - accuracy: 0.8877\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2291 - accuracy: 0.8905\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2231 - accuracy: 0.8930\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.2179 - accuracy: 0.8953\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.2134 - accuracy: 0.8975\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.2095 - accuracy: 0.8993\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2060 - accuracy: 0.9010\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.2029 - accuracy: 0.9025\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 23s 5ms/step - loss: 0.2001 - accuracy: 0.9037\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.1975 - accuracy: 0.9048\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 22s 5ms/step - loss: 0.1952 - accuracy: 0.9059\n",
      "/home/jupyter/model_results/MLP_0.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_0.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.4686 - accuracy: 0.7554\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.4151 - accuracy: 0.7955\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.3624 - accuracy: 0.8255\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2997 - accuracy: 0.8623\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2637 - accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2391 - accuracy: 0.8896\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.2218 - accuracy: 0.8963\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2086 - accuracy: 0.9013\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2011 - accuracy: 0.9042\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1951 - accuracy: 0.9065\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1905 - accuracy: 0.9084\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1870 - accuracy: 0.9098\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1832 - accuracy: 0.9114\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1802 - accuracy: 0.9127\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.1781 - accuracy: 0.9136\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1761 - accuracy: 0.9145\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.1739 - accuracy: 0.9154\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1723 - accuracy: 0.9162\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.1708 - accuracy: 0.9169\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1684 - accuracy: 0.9179\n",
      "/home/jupyter/model_results/MLP_1.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_1.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.4658 - accuracy: 0.7590\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.4053 - accuracy: 0.8079\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.3148 - accuracy: 0.8587\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2480 - accuracy: 0.8906\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2182 - accuracy: 0.9014\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2019 - accuracy: 0.9069\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1921 - accuracy: 0.9101\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1829 - accuracy: 0.9136\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1775 - accuracy: 0.9157\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1716 - accuracy: 0.9178\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1668 - accuracy: 0.9197\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1627 - accuracy: 0.9213\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1588 - accuracy: 0.9229\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1561 - accuracy: 0.9239\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1534 - accuracy: 0.9251\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1512 - accuracy: 0.9260\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1489 - accuracy: 0.9268\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1464 - accuracy: 0.9277\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1446 - accuracy: 0.9284\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1434 - accuracy: 0.9290\n",
      "/home/jupyter/model_results/MLP_2.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_2.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 31s 6ms/step - loss: 0.4680 - accuracy: 0.7579\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.4016 - accuracy: 0.8110\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.3441 - accuracy: 0.8383\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2884 - accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2512 - accuracy: 0.8876\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2290 - accuracy: 0.8972\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2114 - accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2007 - accuracy: 0.9076\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1923 - accuracy: 0.9102\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1842 - accuracy: 0.9137\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1790 - accuracy: 0.9154\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1744 - accuracy: 0.9170\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1714 - accuracy: 0.9179\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1707 - accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1682 - accuracy: 0.9186\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1677 - accuracy: 0.9186\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1668 - accuracy: 0.9193\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1661 - accuracy: 0.9196\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1650 - accuracy: 0.9199\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 31s 6ms/step - loss: 0.1627 - accuracy: 0.9207\n",
      "/home/jupyter/model_results/MLP_3.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_3.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.4604 - accuracy: 0.7699\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.3934 - accuracy: 0.8142\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.3019 - accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.2322 - accuracy: 0.8998\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1998 - accuracy: 0.9124\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1800 - accuracy: 0.9193\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1687 - accuracy: 0.9230\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1616 - accuracy: 0.9249\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1557 - accuracy: 0.9269\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1518 - accuracy: 0.9282\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1490 - accuracy: 0.9289\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1456 - accuracy: 0.9299\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1448 - accuracy: 0.9302\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1426 - accuracy: 0.9310\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1398 - accuracy: 0.9319\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 45s 9ms/step - loss: 0.1376 - accuracy: 0.9327\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1355 - accuracy: 0.9334\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1347 - accuracy: 0.9338\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1338 - accuracy: 0.9341\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1319 - accuracy: 0.9348\n",
      "/home/jupyter/model_results/MLP_4.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_4.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 73s 15ms/step - loss: 0.4582 - accuracy: 0.7736\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.3717 - accuracy: 0.8274\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.2418 - accuracy: 0.8996\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1927 - accuracy: 0.9186\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1688 - accuracy: 0.9263\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1538 - accuracy: 0.9309\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1438 - accuracy: 0.9335\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1357 - accuracy: 0.9361\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1301 - accuracy: 0.9378\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1251 - accuracy: 0.9393\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1216 - accuracy: 0.9405\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1189 - accuracy: 0.9415\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1167 - accuracy: 0.9423\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1153 - accuracy: 0.9428\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1143 - accuracy: 0.9432\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1133 - accuracy: 0.9436\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1134 - accuracy: 0.9436\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1129 - accuracy: 0.9438\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1099 - accuracy: 0.9448\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.1071 - accuracy: 0.9460\n",
      "/home/jupyter/model_results/MLP_5.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_5.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 129s 27ms/step - loss: 0.4550 - accuracy: 0.7766\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.3269 - accuracy: 0.8578\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.2029 - accuracy: 0.9167\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1600 - accuracy: 0.9318\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1381 - accuracy: 0.9384\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 129s 27ms/step - loss: 0.1277 - accuracy: 0.9413\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1189 - accuracy: 0.9439\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1143 - accuracy: 0.9452\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1137 - accuracy: 0.9453\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 129s 27ms/step - loss: 0.1159 - accuracy: 0.9444\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1144 - accuracy: 0.9447\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1057 - accuracy: 0.9477\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1024 - accuracy: 0.9488\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1049 - accuracy: 0.9480\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1098 - accuracy: 0.9464\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1138 - accuracy: 0.9449\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1018 - accuracy: 0.9491\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.0979 - accuracy: 0.9504\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.0995 - accuracy: 0.9499\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 128s 27ms/step - loss: 0.1032 - accuracy: 0.9487\n",
      "/home/jupyter/model_results/MLP_6.pkl -- saved\n",
      "/home/jupyter/model_results/MLP_6.npy -- saved\n",
      "CPU times: user 2h 7min 59s, sys: 36min 11s, total: 2h 44min 10s\n",
      "Wall time: 2h 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MLP_Layers = [[16, 8], [32, 16], [64, 32] ,[32, 16, 8], [64, 32, 16], [128, 64, 32], [256, 128, 64, 32]]\n",
    "REG_Layers = [[0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0]]\n",
    "\n",
    "for i in range(len(MLP_Layers)):\n",
    "    model = get_model(num_users, num_items, mf_dim=8, layers=MLP_Layers[i], reg_layers=REG_Layers[i], reg_mf = [0,0] )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    results[\"MLP_\" + str(i)] = model.fit(train_data, epochs=20)\n",
    "    predictions[\"MLP=\" + str(i)] = model.predict(test_tensor) \n",
    "\n",
    "    spath = \"/home/jupyter/model_results/\" + \"MLP_\" +str(i)+\".pkl\"\n",
    "    with open(spath, 'wb') as file:\n",
    "        pickle.dump(results[\"MLP_\" + str(i)].history, file)\n",
    "    print(f\"{spath} -- saved\")\n",
    "    \n",
    "    path = \"/home/jupyter/model_results/\" + \"MLP_\" +str(i) + \".npy\"\n",
    "    np.save(path, predictions[\"MLP=\" + str(i)])\n",
    "    print(f\"{path} -- saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f21686bc-0eba-40e1-a2fa-c4657c816a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.4731 - accuracy: 0.7520\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.4152 - accuracy: 0.7967\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.3793 - accuracy: 0.8188\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.3395 - accuracy: 0.8328\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.3027 - accuracy: 0.8551\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2786 - accuracy: 0.8685\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2603 - accuracy: 0.8762\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2476 - accuracy: 0.8819\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2373 - accuracy: 0.8875\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2292 - accuracy: 0.8915\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2232 - accuracy: 0.8927\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2179 - accuracy: 0.8940\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.2128 - accuracy: 0.8972\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2085 - accuracy: 0.8995\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2047 - accuracy: 0.9016\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.2016 - accuracy: 0.9028\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1982 - accuracy: 0.9049\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1953 - accuracy: 0.9063\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 29s 6ms/step - loss: 0.1928 - accuracy: 0.9074\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 30s 6ms/step - loss: 0.1906 - accuracy: 0.9084\n",
      "/home/jupyter/model_results/mixture_MLP0_lat16.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP0_lat16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.4728 - accuracy: 0.7524\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.4138 - accuracy: 0.7983\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.3743 - accuracy: 0.8153\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.3375 - accuracy: 0.8301\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.3048 - accuracy: 0.8522\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2810 - accuracy: 0.8683\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2613 - accuracy: 0.8778\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2485 - accuracy: 0.8837\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2383 - accuracy: 0.8880\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2302 - accuracy: 0.8914\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2236 - accuracy: 0.8941\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2180 - accuracy: 0.8966\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2133 - accuracy: 0.8986\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2091 - accuracy: 0.9005\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.2056 - accuracy: 0.9020\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.2026 - accuracy: 0.9033\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1998 - accuracy: 0.9045\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1970 - accuracy: 0.9057\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 44s 9ms/step - loss: 0.1946 - accuracy: 0.9068\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 43s 9ms/step - loss: 0.1924 - accuracy: 0.9077\n",
      "/home/jupyter/model_results/mixture_MLP0_lat32.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP0_lat32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.4889 - accuracy: 0.7421\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.4299 - accuracy: 0.7907\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.3795 - accuracy: 0.8143\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.3676 - accuracy: 0.8186\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.3596 - accuracy: 0.8222\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.3405 - accuracy: 0.8310\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 72s 15ms/step - loss: 0.3081 - accuracy: 0.8552\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2849 - accuracy: 0.8648\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2694 - accuracy: 0.8716\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2577 - accuracy: 0.8768\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2469 - accuracy: 0.8816\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2383 - accuracy: 0.8870\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2316 - accuracy: 0.8902\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2259 - accuracy: 0.8930\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2208 - accuracy: 0.8954\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2162 - accuracy: 0.8975\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2124 - accuracy: 0.8992\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2089 - accuracy: 0.9007\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2059 - accuracy: 0.9020\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 71s 15ms/step - loss: 0.2031 - accuracy: 0.9031\n",
      "/home/jupyter/model_results/mixture_MLP0_lat64.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP0_lat64.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 37s 7ms/step - loss: 0.4689 - accuracy: 0.7553\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.4144 - accuracy: 0.7963\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.3596 - accuracy: 0.8239\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.2936 - accuracy: 0.8643\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.2616 - accuracy: 0.8799\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2398 - accuracy: 0.8894\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2235 - accuracy: 0.8953\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.2125 - accuracy: 0.8997\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2040 - accuracy: 0.9033\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1985 - accuracy: 0.9053\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1933 - accuracy: 0.9074\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1887 - accuracy: 0.9094\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1850 - accuracy: 0.9108\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1829 - accuracy: 0.9115\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1804 - accuracy: 0.9126\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1783 - accuracy: 0.9135\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1763 - accuracy: 0.9143\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1737 - accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1717 - accuracy: 0.9161\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1702 - accuracy: 0.9167\n",
      "/home/jupyter/model_results/mixture_MLP1_lat16.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP1_lat16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 51s 10ms/step - loss: 0.4684 - accuracy: 0.7553\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.4082 - accuracy: 0.7990\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.3471 - accuracy: 0.8372\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 50s 11ms/step - loss: 0.2912 - accuracy: 0.8657\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.2566 - accuracy: 0.8825\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.2358 - accuracy: 0.8907\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.2205 - accuracy: 0.8965\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.2097 - accuracy: 0.9006\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.2022 - accuracy: 0.9035\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1967 - accuracy: 0.9057\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1916 - accuracy: 0.9078\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1870 - accuracy: 0.9096\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1838 - accuracy: 0.9109\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1807 - accuracy: 0.9123\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1785 - accuracy: 0.9132\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1764 - accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1740 - accuracy: 0.9150\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1717 - accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1700 - accuracy: 0.9168\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 50s 10ms/step - loss: 0.1684 - accuracy: 0.9175\n",
      "/home/jupyter/model_results/mixture_MLP1_lat32.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP1_lat32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 79s 16ms/step - loss: 0.4687 - accuracy: 0.7553\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.4095 - accuracy: 0.7995\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.3503 - accuracy: 0.8276\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2936 - accuracy: 0.8634\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2638 - accuracy: 0.8787\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2428 - accuracy: 0.8871\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2280 - accuracy: 0.8913\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2167 - accuracy: 0.8963\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2066 - accuracy: 0.9017\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1993 - accuracy: 0.9042\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1942 - accuracy: 0.9062\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1906 - accuracy: 0.9075\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1875 - accuracy: 0.9089\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1825 - accuracy: 0.9110\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1786 - accuracy: 0.9134\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1762 - accuracy: 0.9142\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1746 - accuracy: 0.9149\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1738 - accuracy: 0.9156\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1731 - accuracy: 0.9158\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1720 - accuracy: 0.9162\n",
      "/home/jupyter/model_results/mixture_MLP1_lat64.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP1_lat64.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.4651 - accuracy: 0.7585\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.4010 - accuracy: 0.8128\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.3120 - accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2508 - accuracy: 0.8894\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2219 - accuracy: 0.9003\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2028 - accuracy: 0.9068\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1908 - accuracy: 0.9111\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1815 - accuracy: 0.9142\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1740 - accuracy: 0.9171\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1681 - accuracy: 0.9193\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1637 - accuracy: 0.9210\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1602 - accuracy: 0.9223\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1564 - accuracy: 0.9238\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1532 - accuracy: 0.9250\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1507 - accuracy: 0.9260\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1485 - accuracy: 0.9268\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1466 - accuracy: 0.9276\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1449 - accuracy: 0.9283\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1434 - accuracy: 0.9289\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1418 - accuracy: 0.9296\n",
      "/home/jupyter/model_results/mixture_MLP2_lat16.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP2_lat16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.4656 - accuracy: 0.7571\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.4012 - accuracy: 0.8128\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.3075 - accuracy: 0.8609\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.2459 - accuracy: 0.8919\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.2162 - accuracy: 0.9028\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1993 - accuracy: 0.9085\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1893 - accuracy: 0.9116\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1800 - accuracy: 0.9151\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1739 - accuracy: 0.9172\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1682 - accuracy: 0.9193\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1638 - accuracy: 0.9209\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1594 - accuracy: 0.9227\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1566 - accuracy: 0.9237\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1539 - accuracy: 0.9248\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1515 - accuracy: 0.9258\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1496 - accuracy: 0.9266\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1475 - accuracy: 0.9274\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1455 - accuracy: 0.9281\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1439 - accuracy: 0.9287\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1424 - accuracy: 0.9293\n",
      "/home/jupyter/model_results/mixture_MLP2_lat32.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP2_lat32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.4653 - accuracy: 0.7592\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.3999 - accuracy: 0.8145\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.3033 - accuracy: 0.8629\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2422 - accuracy: 0.8927\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2153 - accuracy: 0.9022\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1973 - accuracy: 0.9087\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1863 - accuracy: 0.9125\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1779 - accuracy: 0.9155\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1723 - accuracy: 0.9176\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1674 - accuracy: 0.9195\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1627 - accuracy: 0.9213\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1591 - accuracy: 0.9228\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1562 - accuracy: 0.9239\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1532 - accuracy: 0.9250\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1507 - accuracy: 0.9261\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1486 - accuracy: 0.9269\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1465 - accuracy: 0.9277\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1449 - accuracy: 0.9284\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1432 - accuracy: 0.9290\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1419 - accuracy: 0.9296\n",
      "/home/jupyter/model_results/mixture_MLP2_lat64.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP2_lat64.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 37s 8ms/step - loss: 0.4652 - accuracy: 0.7630\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.4074 - accuracy: 0.8098\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.3482 - accuracy: 0.8367\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2843 - accuracy: 0.8718\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2462 - accuracy: 0.8906\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2205 - accuracy: 0.9008\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.2096 - accuracy: 0.9048\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1968 - accuracy: 0.9091\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1871 - accuracy: 0.9118\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 36s 7ms/step - loss: 0.1838 - accuracy: 0.9124\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1750 - accuracy: 0.9169\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1680 - accuracy: 0.9197\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1664 - accuracy: 0.9202\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1648 - accuracy: 0.9207\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1622 - accuracy: 0.9217\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1616 - accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1590 - accuracy: 0.9231\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1581 - accuracy: 0.9234\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 36s 8ms/step - loss: 0.1575 - accuracy: 0.9238\n",
      "/home/jupyter/model_results/mixture_MLP3_lat16.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP3_lat16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.4706 - accuracy: 0.7570\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.4004 - accuracy: 0.8088\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.3384 - accuracy: 0.8417\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2937 - accuracy: 0.8639\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2612 - accuracy: 0.8812\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2393 - accuracy: 0.8912\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2245 - accuracy: 0.8974\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2153 - accuracy: 0.9011\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 50s 11ms/step - loss: 0.2054 - accuracy: 0.9047\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1988 - accuracy: 0.9071\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1928 - accuracy: 0.9093\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1889 - accuracy: 0.9107\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1849 - accuracy: 0.9120\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1830 - accuracy: 0.9125\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1792 - accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1760 - accuracy: 0.9153\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1697 - accuracy: 0.9180\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1675 - accuracy: 0.9190\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1665 - accuracy: 0.9194\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1638 - accuracy: 0.9204\n",
      "/home/jupyter/model_results/mixture_MLP3_lat32.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP3_lat32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 79s 16ms/step - loss: 0.4701 - accuracy: 0.7573\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.3987 - accuracy: 0.8115\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.3302 - accuracy: 0.8463\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2840 - accuracy: 0.8705\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2466 - accuracy: 0.8884\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2259 - accuracy: 0.8965\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2121 - accuracy: 0.9016\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2011 - accuracy: 0.9058\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1914 - accuracy: 0.9100\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1846 - accuracy: 0.9124\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1807 - accuracy: 0.9141\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1768 - accuracy: 0.9155\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1741 - accuracy: 0.9164\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1713 - accuracy: 0.9176\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1684 - accuracy: 0.9187\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1671 - accuracy: 0.9192\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1644 - accuracy: 0.9203\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1619 - accuracy: 0.9213\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1607 - accuracy: 0.9217\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1588 - accuracy: 0.9226\n",
      "/home/jupyter/model_results/mixture_MLP3_lat64.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP3_lat64.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 52s 11ms/step - loss: 0.4621 - accuracy: 0.7695\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.3949 - accuracy: 0.8138\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.3023 - accuracy: 0.8662\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.2301 - accuracy: 0.9010\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1978 - accuracy: 0.9138\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1792 - accuracy: 0.9206\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1653 - accuracy: 0.9249\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1583 - accuracy: 0.9270\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1515 - accuracy: 0.9288\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1474 - accuracy: 0.9301\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1451 - accuracy: 0.9306\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1423 - accuracy: 0.9315\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1407 - accuracy: 0.9320\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1378 - accuracy: 0.9330\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1366 - accuracy: 0.9335\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1357 - accuracy: 0.9338\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1349 - accuracy: 0.9341\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1332 - accuracy: 0.9346\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1323 - accuracy: 0.9349\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 51s 11ms/step - loss: 0.1312 - accuracy: 0.9353\n",
      "/home/jupyter/model_results/mixture_MLP4_lat16.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP4_lat16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 64s 13ms/step - loss: 0.4619 - accuracy: 0.7658\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.3896 - accuracy: 0.8156\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.2928 - accuracy: 0.8717\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.2292 - accuracy: 0.9011\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.2012 - accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1848 - accuracy: 0.9178\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1761 - accuracy: 0.9203\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1648 - accuracy: 0.9241\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1586 - accuracy: 0.9262\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1545 - accuracy: 0.9276\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1509 - accuracy: 0.9285\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1490 - accuracy: 0.9291\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1480 - accuracy: 0.9294\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1454 - accuracy: 0.9303\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1430 - accuracy: 0.9311\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1428 - accuracy: 0.9312\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1400 - accuracy: 0.9320\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1379 - accuracy: 0.9330\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1367 - accuracy: 0.9333\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 63s 13ms/step - loss: 0.1355 - accuracy: 0.9337\n",
      "/home/jupyter/model_results/mixture_MLP4_lat32.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP4_lat32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.4611 - accuracy: 0.7680\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.3860 - accuracy: 0.8184\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2878 - accuracy: 0.8729\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2291 - accuracy: 0.9007\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2044 - accuracy: 0.9109\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1832 - accuracy: 0.9187\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1701 - accuracy: 0.9233\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1597 - accuracy: 0.9266\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1509 - accuracy: 0.9295\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1452 - accuracy: 0.9313\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1413 - accuracy: 0.9324\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1380 - accuracy: 0.9334\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1362 - accuracy: 0.9338\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1345 - accuracy: 0.9344\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1337 - accuracy: 0.9346\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1321 - accuracy: 0.9351\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1302 - accuracy: 0.9358\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1295 - accuracy: 0.9361\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1297 - accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.1293 - accuracy: 0.9361\n",
      "/home/jupyter/model_results/mixture_MLP4_lat64.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP4_lat64.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 79s 16ms/step - loss: 0.4582 - accuracy: 0.7732\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 79s 16ms/step - loss: 0.3736 - accuracy: 0.8260\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.2419 - accuracy: 0.8985\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1880 - accuracy: 0.9199\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1658 - accuracy: 0.9273\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1520 - accuracy: 0.9314\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1425 - accuracy: 0.9341\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1356 - accuracy: 0.9362\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1300 - accuracy: 0.9378\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1252 - accuracy: 0.9392\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1218 - accuracy: 0.9403\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1186 - accuracy: 0.9414\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1161 - accuracy: 0.9423\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1144 - accuracy: 0.9429\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1131 - accuracy: 0.9434\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1122 - accuracy: 0.9437\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1124 - accuracy: 0.9437\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1121 - accuracy: 0.9439\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1108 - accuracy: 0.9445\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 78s 16ms/step - loss: 0.1093 - accuracy: 0.9450\n",
      "/home/jupyter/model_results/mixture_MLP5_lat16.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP5_lat16.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.4587 - accuracy: 0.7739\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.3736 - accuracy: 0.8260\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 92s 19ms/step - loss: 0.2411 - accuracy: 0.8997\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1910 - accuracy: 0.9191\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1678 - accuracy: 0.9268\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1531 - accuracy: 0.9312\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1423 - accuracy: 0.9343\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1347 - accuracy: 0.9364\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1290 - accuracy: 0.9381\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1246 - accuracy: 0.9395\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1213 - accuracy: 0.9405\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1183 - accuracy: 0.9416\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1159 - accuracy: 0.9424\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1139 - accuracy: 0.9432\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1122 - accuracy: 0.9438\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1114 - accuracy: 0.9441\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1111 - accuracy: 0.9443\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1115 - accuracy: 0.9442\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1107 - accuracy: 0.9446\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 93s 19ms/step - loss: 0.1080 - accuracy: 0.9456\n",
      "/home/jupyter/model_results/mixture_MLP5_lat32.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP5_lat32.npy -- saved\n",
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.4574 - accuracy: 0.7741\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.3683 - accuracy: 0.8290\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.2329 - accuracy: 0.9031\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1842 - accuracy: 0.9214\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1626 - accuracy: 0.9284\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.1494 - accuracy: 0.9319\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.1401 - accuracy: 0.9348\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1331 - accuracy: 0.9368\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1273 - accuracy: 0.9386\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1232 - accuracy: 0.9400\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1199 - accuracy: 0.9411\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1169 - accuracy: 0.9421\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1146 - accuracy: 0.9429\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1129 - accuracy: 0.9436\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1115 - accuracy: 0.9441\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 117s 24ms/step - loss: 0.1113 - accuracy: 0.9442\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.1111 - accuracy: 0.9444\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.1079 - accuracy: 0.9456\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.1058 - accuracy: 0.9464\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 116s 24ms/step - loss: 0.1050 - accuracy: 0.9467\n",
      "/home/jupyter/model_results/mixture_MLP5_lat64.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP5_lat64.npy -- saved\n",
      "Epoch 1/20\n",
      " 655/4805 [===>..........................] - ETA: 1:55 - loss: 0.5212 - accuracy: 0.7068"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_2318/3189640464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREG_Layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLP_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_N_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"lat_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLP_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_N_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"lat_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "latent_dimension = [16, 32, 64]\n",
    "MLP_Layers = [[16, 8], [32, 16], [64, 32] ,[32, 16, 8], [64, 32, 16], [128, 64, 32], [256, 128, 64, 32]]\n",
    "REG_Layers = [[0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0]]\n",
    "\n",
    "for index, value in enumerate(MLP_Layers):\n",
    "    for j in latent_dimension: \n",
    "        model = get_model(num_users, num_items, mf_dim=j, layers=value, reg_layers=REG_Layers[index], reg_mf = [0,0])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        results[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)] = model.fit(train_data, epochs=20)\n",
    "        predictions[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)] = model.predict(test_tensor) \n",
    "\n",
    "        spath = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(index) + \"_lat\" + str(j) + \".pkl\"\n",
    "        with open(spath, 'wb') as file:\n",
    "            pickle.dump(results[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)].history, file)\n",
    "        print(f\"{spath} -- saved\")\n",
    "\n",
    "        path = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(index) + \"_lat\" + str(j) + \".npy\"\n",
    "        np.save(path, predictions[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)])\n",
    "        print(f\"{path} -- saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab01d869-cdc0-4e6c-8c83-430fcc96ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.4547 - accuracy: 0.7770\n",
      "Epoch 2/20\n",
      "4805/4805 [==============================] - 135s 28ms/step - loss: 0.3312 - accuracy: 0.8558\n",
      "Epoch 3/20\n",
      "4805/4805 [==============================] - 135s 28ms/step - loss: 0.2036 - accuracy: 0.9167\n",
      "Epoch 4/20\n",
      "4805/4805 [==============================] - 135s 28ms/step - loss: 0.1603 - accuracy: 0.9320\n",
      "Epoch 5/20\n",
      "4805/4805 [==============================] - 135s 28ms/step - loss: 0.1391 - accuracy: 0.9381\n",
      "Epoch 6/20\n",
      "4805/4805 [==============================] - 137s 29ms/step - loss: 0.1271 - accuracy: 0.9413\n",
      "Epoch 7/20\n",
      "4805/4805 [==============================] - 138s 29ms/step - loss: 0.1191 - accuracy: 0.9436\n",
      "Epoch 8/20\n",
      "4805/4805 [==============================] - 137s 29ms/step - loss: 0.1144 - accuracy: 0.9449\n",
      "Epoch 9/20\n",
      "4805/4805 [==============================] - 137s 29ms/step - loss: 0.1123 - accuracy: 0.9456\n",
      "Epoch 10/20\n",
      "4805/4805 [==============================] - 137s 29ms/step - loss: 0.1144 - accuracy: 0.9448\n",
      "Epoch 11/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1131 - accuracy: 0.9451\n",
      "Epoch 12/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1120 - accuracy: 0.9455\n",
      "Epoch 13/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1080 - accuracy: 0.9469\n",
      "Epoch 14/20\n",
      "4805/4805 [==============================] - 136s 28ms/step - loss: 0.1078 - accuracy: 0.9470\n",
      "Epoch 15/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1108 - accuracy: 0.9459\n",
      "Epoch 16/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1028 - accuracy: 0.9486\n",
      "Epoch 17/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1043 - accuracy: 0.9481\n",
      "Epoch 18/20\n",
      "4805/4805 [==============================] - 137s 28ms/step - loss: 0.1070 - accuracy: 0.9472\n",
      "Epoch 19/20\n",
      "4805/4805 [==============================] - 135s 28ms/step - loss: 0.1065 - accuracy: 0.9474\n",
      "Epoch 20/20\n",
      "4805/4805 [==============================] - 135s 28ms/step - loss: 0.1043 - accuracy: 0.9482\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_4231/3255127048.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmf_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREG_Layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLP_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_N_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"lat_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MLP_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_N_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"lat_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "latent_dimension = [16, 32, 64]\n",
    "MLP_Layers = [[16, 8], [32, 16], [64, 32] ,[32, 16, 8], [64, 32, 16], [128, 64, 32], [256, 128, 64, 32]]\n",
    "REG_Layers = [[0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0]]\n",
    "\n",
    "for index, value in enumerate(MLP_Layers):\n",
    "    if index == 6:\n",
    "        for j in latent_dimension: \n",
    "            model = get_model(num_users, num_items, mf_dim=j, layers=value, reg_layers=REG_Layers[index], reg_mf = [0,0])\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            results[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)] = model.fit(train_data, epochs=20)\n",
    "            predictions[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)] = model.predict(test_tensor) \n",
    "\n",
    "            spath = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(index) + \"_lat\" + str(j) + \".pkl\"\n",
    "            with open(spath, 'wb') as file:\n",
    "                pickle.dump(results[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)].history, file)\n",
    "            print(f\"{spath} -- saved\")\n",
    "\n",
    "            path = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(index) + \"_lat\" + str(j) + \".npy\"\n",
    "            np.save(path, predictions[\"MLP_\" + str(i) + \"_N_\" + \"lat_\" + str(j)])\n",
    "            print(f\"{path} -- saved\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594a8695-d9b2-4beb-ab91-f32c172313c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef891a-9ad4-49ea-bd4f-1d7204eee1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e0d586e-8b58-4555-ab1d-80f7ae133406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5116be35-7a8c-4d1a-80e1-a027bb919077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2403/2403 [==============================] - 70s 29ms/step - loss: 0.4591 - accuracy: 0.7723\n",
      "Epoch 2/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.3617 - accuracy: 0.8361\n",
      "Epoch 3/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.2261 - accuracy: 0.9045\n",
      "Epoch 4/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1796 - accuracy: 0.9210\n",
      "Epoch 5/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1599 - accuracy: 0.9270\n",
      "Epoch 6/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1489 - accuracy: 0.9302\n",
      "Epoch 7/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1436 - accuracy: 0.9311\n",
      "Epoch 8/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1398 - accuracy: 0.9322\n",
      "Epoch 9/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1397 - accuracy: 0.9319\n",
      "Epoch 10/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1425 - accuracy: 0.9306\n",
      "Epoch 11/20\n",
      "2403/2403 [==============================] - 68s 29ms/step - loss: 0.1427 - accuracy: 0.9306\n",
      "Epoch 12/20\n",
      "2403/2403 [==============================] - 68s 28ms/step - loss: 0.1430 - accuracy: 0.9303\n",
      "Epoch 13/20\n",
      "2403/2403 [==============================] - 68s 28ms/step - loss: 0.1432 - accuracy: 0.9301\n",
      "Epoch 14/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1445 - accuracy: 0.9295\n",
      "Epoch 15/20\n",
      "2403/2403 [==============================] - 68s 28ms/step - loss: 0.1377 - accuracy: 0.9319\n",
      "Epoch 16/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1405 - accuracy: 0.9310\n",
      "Epoch 17/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1485 - accuracy: 0.9280\n",
      "Epoch 18/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1420 - accuracy: 0.9301\n",
      "Epoch 19/20\n",
      "2403/2403 [==============================] - 69s 29ms/step - loss: 0.1301 - accuracy: 0.9345\n",
      "Epoch 20/20\n",
      "2403/2403 [==============================] - 68s 28ms/step - loss: 0.1232 - accuracy: 0.9372\n",
      "/home/jupyter/model_results/mixture_MLP6_lat1.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP6_lat1.npy -- saved\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_users, num_items, mf_dim=16, layers=[256, 128, 64, 32], reg_layers=[0,0,0,0], reg_mf = [0,0])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "results[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(1)] = model.fit(train_data, epochs=20)\n",
    "predictions[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(1)] = model.predict(test_tensor) \n",
    "\n",
    "spath = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(6) + \"_lat\" + str(1) + \".pkl\"\n",
    "with open(spath, 'wb') as file:\n",
    "    pickle.dump(results[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(1)].history, file)\n",
    "print(f\"{spath} -- saved\")\n",
    "\n",
    "path = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(6) + \"_lat\" + str(1) + \".npy\"\n",
    "np.save(path, predictions[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(1)])\n",
    "print(f\"{path} -- saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be27ada-7f06-4999-9f40-459e1c66d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2403/2403 [==============================] - 77s 31ms/step - loss: 0.4591 - accuracy: 0.7727\n",
      "Epoch 2/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.3566 - accuracy: 0.8395\n",
      "Epoch 3/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.2195 - accuracy: 0.9078\n",
      "Epoch 4/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1748 - accuracy: 0.9233\n",
      "Epoch 5/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1564 - accuracy: 0.9283\n",
      "Epoch 6/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1453 - accuracy: 0.9310\n",
      "Epoch 7/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1400 - accuracy: 0.9326\n",
      "Epoch 8/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1363 - accuracy: 0.9335\n",
      "Epoch 9/20\n",
      "2403/2403 [==============================] - 75s 31ms/step - loss: 0.1364 - accuracy: 0.9332\n",
      "Epoch 10/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1406 - accuracy: 0.9316\n",
      "Epoch 11/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1412 - accuracy: 0.9311\n",
      "Epoch 12/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1344 - accuracy: 0.9334\n",
      "Epoch 13/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1269 - accuracy: 0.9363\n",
      "Epoch 14/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1217 - accuracy: 0.9383\n",
      "Epoch 15/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1242 - accuracy: 0.9378\n",
      "Epoch 16/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1389 - accuracy: 0.9325\n",
      "Epoch 17/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1417 - accuracy: 0.9313\n",
      "Epoch 18/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1362 - accuracy: 0.9329\n",
      "Epoch 19/20\n",
      "2403/2403 [==============================] - 76s 32ms/step - loss: 0.1255 - accuracy: 0.9369\n",
      "Epoch 20/20\n",
      "2403/2403 [==============================] - 76s 31ms/step - loss: 0.1188 - accuracy: 0.9393\n",
      "/home/jupyter/model_results/mixture_MLP6_lat2.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP6_lat2.npy -- saved\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_users, num_items, mf_dim=32, layers=[256, 128, 64, 32], reg_layers=[0,0,0,0], reg_mf = [0,0])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "results[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(2)] = model.fit(train_data, epochs=20)\n",
    "predictions[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(2)] = model.predict(test_tensor) \n",
    "\n",
    "spath = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(6) + \"_lat\" + str(2) + \".pkl\"\n",
    "with open(spath, 'wb') as file:\n",
    "    pickle.dump(results[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(2)].history, file)\n",
    "print(f\"{spath} -- saved\")\n",
    "\n",
    "path = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(6) + \"_lat\" + str(2) + \".npy\"\n",
    "np.save(path, predictions[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(2)])\n",
    "print(f\"{path} -- saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c39379cb-0f5a-4011-bc04-7cf974fa63a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2403/2403 [==============================] - 90s 37ms/step - loss: 0.4590 - accuracy: 0.7728\n",
      "Epoch 2/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.3599 - accuracy: 0.8369\n",
      "Epoch 3/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.2209 - accuracy: 0.9069\n",
      "Epoch 4/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1751 - accuracy: 0.9231\n",
      "Epoch 5/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1564 - accuracy: 0.9285\n",
      "Epoch 6/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1467 - accuracy: 0.9307\n",
      "Epoch 7/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1404 - accuracy: 0.9324\n",
      "Epoch 8/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1386 - accuracy: 0.9325\n",
      "Epoch 9/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1378 - accuracy: 0.9327\n",
      "Epoch 10/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1390 - accuracy: 0.9320\n",
      "Epoch 11/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1400 - accuracy: 0.9315\n",
      "Epoch 12/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1412 - accuracy: 0.9308\n",
      "Epoch 13/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1402 - accuracy: 0.9314\n",
      "Epoch 14/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1429 - accuracy: 0.9302\n",
      "Epoch 15/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1435 - accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1393 - accuracy: 0.9312\n",
      "Epoch 17/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1369 - accuracy: 0.9320\n",
      "Epoch 18/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1294 - accuracy: 0.9348\n",
      "Epoch 19/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1220 - accuracy: 0.9375\n",
      "Epoch 20/20\n",
      "2403/2403 [==============================] - 89s 37ms/step - loss: 0.1189 - accuracy: 0.9386\n",
      "/home/jupyter/model_results/mixture_MLP6_lat3.pkl -- saved\n",
      "/home/jupyter/model_results/mixture_MLP6_lat3.npy -- saved\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_users, num_items, mf_dim=64, layers=[256, 128, 64, 32], reg_layers=[0,0,0,0], reg_mf = [0,0])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "results[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(3)] = model.fit(train_data, epochs=20)\n",
    "predictions[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(3)] = model.predict(test_tensor) \n",
    "\n",
    "spath = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(6) + \"_lat\" + str(3) + \".pkl\"\n",
    "with open(spath, 'wb') as file:\n",
    "    pickle.dump(results[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(3)].history, file)\n",
    "print(f\"{spath} -- saved\")\n",
    "\n",
    "path = \"/home/jupyter/model_results/\" + \"mixture_\" + \"MLP\" + str(6) + \"_lat\" + str(3) + \".npy\"\n",
    "np.save(path, predictions[\"MLP_\" + str(6) + \"_N_\" + \"lat_\" + str(3)])\n",
    "print(f\"{path} -- saved\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
