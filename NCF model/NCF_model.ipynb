{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83a82f6-b897-436f-9166-e07be7e47c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os \n",
    "import ast\n",
    "import json \n",
    "import time\n",
    "import math\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77169811-ddab-4de0-a5b4-a38bdce24fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/jupyter\n"
     ]
    }
   ],
   "source": [
    "#check working directory\n",
    "current_dir = os.getcwd() \n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c418db",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98c6409-a41b-4170-876f-aeee3244c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory\n",
    "direc = \"gs://ncf446-201929129/rdd_data_metadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffc457d-a8d0-4a9d-8b79-094602f073f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read parquet files, every one of whcih is made of 10 raw json files which is equivalent to 1000 playlists\n",
    "fpath = []\n",
    "\n",
    "for i in range(1, 6, 1):\n",
    "    \n",
    "    path = direc + \"batch_\" + str(i)+'/' \n",
    "    fpath.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4debb4e7-75fd-470c-ae65-3da51c021636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine to become a big dataframe\n",
    "def load(): \n",
    "    \n",
    "    for index, value in tqdm(enumerate(fpath)):\n",
    "        \n",
    "        file = pd.read_parquet(value)\n",
    "        \n",
    "        if index == 0: #first file\n",
    "            df = file \n",
    "            \n",
    "        else:\n",
    "            df = pd.concat([df, file], axis = 0) #combine files together into one big dataframe\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af01a924-bb37-4be4-8bf5-911ea1ca0d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "df = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c241592-bae4-4e5f-beee-8e543630bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (50000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of dataframe: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5e3d18-ad85-4c84-8392-2cff33e966f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>name</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>num_albums</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>tracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Throwbacks</td>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'pos': '0', 'track_name': 'Lose Control (fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Awesome Playlist</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'pos': '0', 'track_name': 'Eye of the Tiger'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>korean</td>\n",
       "      <td>64</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'pos': '0', 'track_name': 'Like You', 'track...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mat</td>\n",
       "      <td>126</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'pos': '0', 'track_name': 'Danse macabre', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>90s</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'pos': '0', 'track_name': 'Tonight, Tonight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid              name  num_tracks  num_albums  num_followers  \\\n",
       "0    0        Throwbacks          52          47              1   \n",
       "1    1  Awesome Playlist          39          23              1   \n",
       "2    2           korean           64          51              1   \n",
       "3    3               mat         126         107              1   \n",
       "4    4               90s          17          16              2   \n",
       "\n",
       "                                              tracks  \n",
       "0  [{'pos': '0', 'track_name': 'Lose Control (fea...  \n",
       "1  [{'pos': '0', 'track_name': 'Eye of the Tiger'...  \n",
       "2  [{'pos': '0', 'track_name': 'Like You', 'track...  \n",
       "3  [{'pos': '0', 'track_name': 'Danse macabre', '...  \n",
       "4  [{'pos': '0', 'track_name': 'Tonight, Tonight'...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1a03519-0fbf-4d9a-844e-6dcdfdb36795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pidNTrack():\n",
    "\n",
    "    trackList = []\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows()): #iterate through each row in dataframe\n",
    "        for track in row['tracks']:\n",
    "            trackList.append([ row['pid'],track['track_uri']]) \n",
    "\n",
    "    songPlaylist = pd.DataFrame(trackList, columns=[ 'pid', 'track_uri']) #create dataframe\n",
    "    \n",
    "    print(songPlaylist.shape)\n",
    "    \n",
    "    return songPlaylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af52af1-7f77-47f5-8123-42da7fc1df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:15, 3137.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3348258, 2)\n"
     ]
    }
   ],
   "source": [
    "new_df = load_pidNTrack() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6cedb5-de92-4c41-be0b-0a4f91d7c145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:6I9VzXrHxO9rA9A5euc8Ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0WqIKmW4BTrj3eJFmnCKMv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:1AWQoqb9bSvzTjaLralEkT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:1lzr43nnXAijIGYnCT8M8H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid                             track_uri\n",
       "0    0  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\n",
       "1    0  spotify:track:6I9VzXrHxO9rA9A5euc8Ak\n",
       "2    0  spotify:track:0WqIKmW4BTrj3eJFmnCKMv\n",
       "3    0  spotify:track:1AWQoqb9bSvzTjaLralEkT\n",
       "4    0  spotify:track:1lzr43nnXAijIGYnCT8M8H"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3f886-a6e3-44df-bed3-b5f89f0b8761",
   "metadata": {},
   "source": [
    "#### Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d65cfd2-0725-468a-b676-4cd2acf5726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(): #encode track_uri to integer so that model can analyse and pattern mine\n",
    "\n",
    "    label_encoder = LabelEncoder() #sklearn module to encode\n",
    "    encode_df = new_df.copy() #dont change the original dataframe\n",
    "    encode_df[\"encoded_track_uri\"] = label_encoder.fit_transform(encode_df[\"track_uri\"]) #attach the original info for convienience\n",
    "\n",
    "    return encode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78b7cb22-9542-4d23-b3d3-2c68887d4cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of the encode_df dataframe: (3348258, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>encoded_track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0UaMYEvWZi0ZqiDOoHU3YI</td>\n",
       "      <td>29183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:6I9VzXrHxO9rA9A5euc8Ak</td>\n",
       "      <td>369182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:0WqIKmW4BTrj3eJFmnCKMv</td>\n",
       "      <td>31359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:1AWQoqb9bSvzTjaLralEkT</td>\n",
       "      <td>68783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>spotify:track:1lzr43nnXAijIGYnCT8M8H</td>\n",
       "      <td>104309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid                             track_uri  encoded_track_uri\n",
       "0    0  spotify:track:0UaMYEvWZi0ZqiDOoHU3YI              29183\n",
       "1    0  spotify:track:6I9VzXrHxO9rA9A5euc8Ak             369182\n",
       "2    0  spotify:track:0WqIKmW4BTrj3eJFmnCKMv              31359\n",
       "3    0  spotify:track:1AWQoqb9bSvzTjaLralEkT              68783\n",
       "4    0  spotify:track:1lzr43nnXAijIGYnCT8M8H             104309"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_df = encode()\n",
    "print(f'dimension of the encode_df dataframe: {encode_df.shape}')\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da8e13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of groupedDF dataframe: (50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>encoded_track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[spotify:track:0UaMYEvWZi0ZqiDOoHU3YI, spotify...</td>\n",
       "      <td>[29183, 369182, 31359, 68783, 104309, 31987, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[spotify:track:2HHtWyy5CgaQbC7XSoOb0e, spotify...</td>\n",
       "      <td>[134057, 80210, 232086, 83300, 81170, 201792, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[spotify:track:74tqql9zP6JjF5hjkHHUXp, spotify...</td>\n",
       "      <td>[415068, 273492, 275926, 97422, 30879, 122366,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[spotify:track:4WJ7UMD4i6DOPzyXU5pZSz, spotify...</td>\n",
       "      <td>[265305, 78749, 396965, 109420, 320661, 292327...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[spotify:track:4iCGSi1RonREsPtfEKYj5b, spotify...</td>\n",
       "      <td>[276674, 343402, 36247, 446621, 401973, 208252...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid                                          track_uri  \\\n",
       "0    0  [spotify:track:0UaMYEvWZi0ZqiDOoHU3YI, spotify...   \n",
       "1    1  [spotify:track:2HHtWyy5CgaQbC7XSoOb0e, spotify...   \n",
       "2    2  [spotify:track:74tqql9zP6JjF5hjkHHUXp, spotify...   \n",
       "3    3  [spotify:track:4WJ7UMD4i6DOPzyXU5pZSz, spotify...   \n",
       "4    4  [spotify:track:4iCGSi1RonREsPtfEKYj5b, spotify...   \n",
       "\n",
       "                                   encoded_track_uri  \n",
       "0  [29183, 369182, 31359, 68783, 104309, 31987, 3...  \n",
       "1  [134057, 80210, 232086, 83300, 81170, 201792, ...  \n",
       "2  [415068, 273492, 275926, 97422, 30879, 122366,...  \n",
       "3  [265305, 78749, 396965, 109420, 320661, 292327...  \n",
       "4  [276674, 343402, 36247, 446621, 401973, 208252...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the tracks back into a list\n",
    "groupedDF = encode_df.groupby('pid').agg(list).reset_index() #group by pid and aggregate the track_uri into a list\n",
    "print(f\"dimension of groupedDF dataframe: {groupedDF.shape}\") #check shape make sure no mistake\n",
    "groupedDF.head()\n",
    "#groupedDF['pid'] #print this to check if the pid values are unqiue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44008b33-2238-4083-9282-4c0665d4048e",
   "metadata": {},
   "source": [
    "#### We only want to consider playlist that has more than 20 tracks.   \n",
    "41302 out of 50000 playlists have more than 20 tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "667a3219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension: (41302, 3)\n"
     ]
    }
   ],
   "source": [
    "groupedDF = groupedDF[groupedDF['encoded_track_uri'].apply(lambda x: len(x) > 20)] \n",
    "print(f\"dimension: {groupedDF.shape}\")\n",
    "# groupedDF2 = groupedDF[groupedDF['track_uri'].apply(lambda x: len(x) > 20)] \n",
    "# groupedDF1.equals(groupedDF2)  #check if the two dataframes are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e796b4e-74d1-4cde-a960-7febbd0dcf5c",
   "metadata": {},
   "source": [
    "#### train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f68c23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train dataset: (33041, 3)\n",
      "shape of test dataset: (8261, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(groupedDF, test_size=0.2, random_state=123) # we will use train_df to train the model and test_df to evaluate the model\n",
    "print(f\"shape of train dataset: {train_df.shape}\")\n",
    "print(f\"shape of test dataset: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96a1041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>encoded_track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47929</th>\n",
       "      <td>140929</td>\n",
       "      <td>[spotify:track:7tTElNyvXsfFcxDXIiH5cm, spotify...</td>\n",
       "      <td>[450680, 54561, 149995, 448139, 232214, 110882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30040</th>\n",
       "      <td>123040</td>\n",
       "      <td>[spotify:track:2QilECqmzYBoI6yS5D8ftS, spotify...</td>\n",
       "      <td>[142911, 11889, 202230, 153176, 74998, 407598,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>101515</td>\n",
       "      <td>[spotify:track:7d23MhPFE9eB3U8DPRirnL, spotify...</td>\n",
       "      <td>[435114, 102071, 300781, 421948, 261913, 11343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>100915</td>\n",
       "      <td>[spotify:track:1wHZx0LgzFHyeIZkUydNXq, spotify...</td>\n",
       "      <td>[114165, 19037, 244393, 416496, 186082, 58233,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24877</th>\n",
       "      <td>117877</td>\n",
       "      <td>[spotify:track:3ZzrBfE1RChGRCraiB9G2P, spotify...</td>\n",
       "      <td>[210045, 108028, 434986, 239284, 10705, 123744...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid                                          track_uri  \\\n",
       "47929  140929  [spotify:track:7tTElNyvXsfFcxDXIiH5cm, spotify...   \n",
       "30040  123040  [spotify:track:2QilECqmzYBoI6yS5D8ftS, spotify...   \n",
       "8515   101515  [spotify:track:7d23MhPFE9eB3U8DPRirnL, spotify...   \n",
       "7915   100915  [spotify:track:1wHZx0LgzFHyeIZkUydNXq, spotify...   \n",
       "24877  117877  [spotify:track:3ZzrBfE1RChGRCraiB9G2P, spotify...   \n",
       "\n",
       "                                       encoded_track_uri  \n",
       "47929  [450680, 54561, 149995, 448139, 232214, 110882...  \n",
       "30040  [142911, 11889, 202230, 153176, 74998, 407598,...  \n",
       "8515   [435114, 102071, 300781, 421948, 261913, 11343...  \n",
       "7915   [114165, 19037, 244393, 416496, 186082, 58233,...  \n",
       "24877  [210045, 108028, 434986, 239284, 10705, 123744...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "# train_df.to_csv(\"C:/Users/Tiam Tee/Documents/Spotify100M_data_project/Models/Data/trainWithoutNegative.csv\", sep='\\t', encoding='utf-8') #save to local disk for future convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035936cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>encoded_track_uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9489</th>\n",
       "      <td>102489</td>\n",
       "      <td>[spotify:track:3fqwjXwUGN6vbzIwvyFMhx, spotify...</td>\n",
       "      <td>[215623, 393454, 69228, 4854, 439226, 165886, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>10787</td>\n",
       "      <td>[spotify:track:2dOTkLZFbpNXrhc24CnTFd, spotify...</td>\n",
       "      <td>[154957, 453219, 104309, 389316, 37543, 158183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42699</th>\n",
       "      <td>135699</td>\n",
       "      <td>[spotify:track:4UXpJDvdsfneLvT09oJocg, spotify...</td>\n",
       "      <td>[263624, 78766, 68030, 263570, 266054, 190141,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12545</th>\n",
       "      <td>105545</td>\n",
       "      <td>[spotify:track:5VbBBiLl5Y9NGikFrSTdO6, spotify...</td>\n",
       "      <td>[323172, 426350, 386201, 343344, 294639, 31349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>100888</td>\n",
       "      <td>[spotify:track:2BstRQGodshjGpeDGQiNgo, spotify...</td>\n",
       "      <td>[128887, 75980, 51200, 368949, 233305, 438419,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid                                          track_uri  \\\n",
       "9489   102489  [spotify:track:3fqwjXwUGN6vbzIwvyFMhx, spotify...   \n",
       "2787    10787  [spotify:track:2dOTkLZFbpNXrhc24CnTFd, spotify...   \n",
       "42699  135699  [spotify:track:4UXpJDvdsfneLvT09oJocg, spotify...   \n",
       "12545  105545  [spotify:track:5VbBBiLl5Y9NGikFrSTdO6, spotify...   \n",
       "7888   100888  [spotify:track:2BstRQGodshjGpeDGQiNgo, spotify...   \n",
       "\n",
       "                                       encoded_track_uri  \n",
       "9489   [215623, 393454, 69228, 4854, 439226, 165886, ...  \n",
       "2787   [154957, 453219, 104309, 389316, 37543, 158183...  \n",
       "42699  [263624, 78766, 68030, 263570, 266054, 190141,...  \n",
       "12545  [323172, 426350, 386201, 343344, 294639, 31349...  \n",
       "7888   [128887, 75980, 51200, 368949, 233305, 438419,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n",
    "# test_df.to_csv(\"C:/Users/Tiam Tee/Documents/Spotify100M_data_project/Models/Data/testWithoutNegative.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dafaa4a-c6dd-4b77-bb45-a7621fb5fb2e",
   "metadata": {},
   "source": [
    "From the following output, we can see that the average number of tracks in all playlists in the train test is 78 and median is 61 while in the test set, the mean is 79 and median is 63. \n",
    "This is a very important piece of information because in both train and test dataframe, we only have positive data and zero negetive data. Hence, we have to manually create negative data and form a new balance dataset. positive data here refers to tracks with label as 1 and negative means track with label as zero. The label 0 and 1 justify if a track is in a playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd5f68bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    33041.000000\n",
      "mean        77.999395\n",
      "std         52.692228\n",
      "min         21.000000\n",
      "25%         37.000000\n",
      "50%         61.000000\n",
      "75%        104.000000\n",
      "max        250.000000\n",
      "Name: count_track, dtype: float64\n",
      "count    8261.000000\n",
      "mean       78.879797\n",
      "std        53.314190\n",
      "min        21.000000\n",
      "25%        38.000000\n",
      "50%        63.000000\n",
      "75%       104.000000\n",
      "max       250.000000\n",
      "Name: count_track, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Copy_train_df = train_df.copy() #make a copy and assign the content to a new variable jsut in case we might mutate original data in the following computations\n",
    "Copy_test_df = test_df.copy()\n",
    "\n",
    "Copy_train_df['count_track'] = train_df['encoded_track_uri'].apply(lambda x: len(x)) #calcuate amount of songs in every playlist and attach the orignal dataset with a enw column\n",
    "Copy_test_df['count_track'] = test_df['encoded_track_uri'].apply(lambda x: len(x))\n",
    "\n",
    "print(Copy_train_df['count_track'].describe())\n",
    "print(Copy_test_df['count_track'].describe()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112e001-63b5-4bd2-b5f6-daaf88776a7f",
   "metadata": {},
   "source": [
    "#### Preparing negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150cedef-deb6-4a9b-9065-8241173eb65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of unique tracks in all playlists: 457016\n"
     ]
    }
   ],
   "source": [
    "# make a list of all unique track items.\n",
    "distinct_trackList = encode_df['encoded_track_uri'].unique().tolist() \n",
    "\n",
    "print(f'the number of unique tracks in all playlists: {len(distinct_trackList)}')\n",
    "\n",
    "# len(encode_df['encoded_track_uri'].unique().tolist()) == len(encode_df['track_uri'].unique().tolist()) #double make sure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c139c0-e3cd-40bb-b0c5-699971a06ec2",
   "metadata": {},
   "source": [
    "The idea here is that for every playlist, we generate another column of negative list by random sample n items from a set of items that is not in encoded_track_uri list but in distinct list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c68a764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNegative(distinct_trackList, df, negatives):\n",
    "    \n",
    "    '''\n",
    "    arguments:\n",
    "    distinct_trackList: list of all distinct track_uri  #in our code: encode_df['track_uri'].unique().tolist()\n",
    "    df: dataframe of pid and list of encoded_track_uri\n",
    "    negatives: number of negative samples to be created for each pid\n",
    "    '''\n",
    "    \n",
    "    df_ARR = np.array(df)\n",
    "    negative_list = []\n",
    "    \n",
    "    for pidNList in tqdm(df_ARR):\n",
    "        NpidNList = list()\n",
    "        pid = pidNList[0]\n",
    "        trackList = pidNList[1] \n",
    "        NpidNList.append(pid)\n",
    "        sampling = random.sample(set(distinct_trackList) - set(trackList), negatives) #set only keeps unique items\n",
    "        NpidNList.append(sampling)     \n",
    "        negative_list.append(NpidNList)\n",
    "        \n",
    "    negative_list = pd.DataFrame(negative_list, columns = ['pid', 'tracks_with_label0'])\n",
    "    \n",
    "    return negative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca89502d-81a1-41b5-bed9-aac08d8c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainWnegative = createNegative(distinct_trackList, train_df.loc[:, ['pid', 'encoded_track_uri']], 61) \n",
    "# 61 is the median hence we use 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd2ce13-84ab-4cfe-8bbf-7169cd1932a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainWnegative.to_csv(\"trainWnegative61.csv\")\n",
    "trainWnegative = pd.read_csv(\"trainWnegative61.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca53d232-cd80-4ffb-bb12-fbbcf453ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainWnegative['tracks_with_label0'] = trainWnegative['tracks_with_label0'].apply(ast.literal_eval) \n",
    "# pandas might have converted the list into string in the saving process for memory efficiency hence we need to convert it back .\n",
    "trainWnegative = trainWnegative.explode('tracks_with_label0') #explode the list \n",
    "trainWnegative['label'] = 0 #assign label to it \n",
    "trainWnegative = trainWnegative.loc[:,['pid', 'tracks_with_label0', 'label']]\n",
    "trainWnegative = trainWnegative.reset_index(drop=True).rename(columns={'tracks_with_label0': 'track_id'}) #reset index and rename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19f3c8c9-1ee5-4ccc-bef7-14351560c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140929</td>\n",
       "      <td>305528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140929</td>\n",
       "      <td>132913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140929</td>\n",
       "      <td>259685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140929</td>\n",
       "      <td>190244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140929</td>\n",
       "      <td>278977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid track_id  label\n",
       "0  140929   305528      0\n",
       "1  140929   132913      0\n",
       "2  140929   259685      0\n",
       "3  140929   190244      0\n",
       "4  140929   278977      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWnegative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6676377-5b37-4da6-9959-37de16901c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[:,['pid', 'encoded_track_uri']]\n",
    "train_label_1 = train_df.reset_index(drop=True).rename(columns={'encoded_track_uri': 'track_id'}) #make sure the column name is the same as the negative dataframe so we can merge them together \n",
    "train_label_1 = train_label_1.explode('track_id')\n",
    "train_label_1['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f3b2c22-e8c3-4a44-a6c0-d844fbda7a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140929</td>\n",
       "      <td>450680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140929</td>\n",
       "      <td>54561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140929</td>\n",
       "      <td>149995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140929</td>\n",
       "      <td>448139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140929</td>\n",
       "      <td>232214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid track_id  label\n",
       "0  140929   450680      1\n",
       "0  140929    54561      1\n",
       "0  140929   149995      1\n",
       "0  140929   448139      1\n",
       "0  140929   232214      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c901be45-0dba-441f-932f-8e8b21e0abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF = pd.concat([trainWnegative, train_label_1], axis=0)\n",
    "train_DF = train_DF.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c40b76ec-1f46-488b-96ac-3f9d8464af2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284133</th>\n",
       "      <td>114005</td>\n",
       "      <td>36279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16284</th>\n",
       "      <td>123250</td>\n",
       "      <td>325426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14884</th>\n",
       "      <td>134397</td>\n",
       "      <td>456934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26716</th>\n",
       "      <td>1457</td>\n",
       "      <td>446730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21282</th>\n",
       "      <td>104337</td>\n",
       "      <td>385110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pid track_id  label\n",
       "284133  114005    36279      0\n",
       "16284   123250   325426      1\n",
       "14884   134397   456934      1\n",
       "26716     1457   446730      1\n",
       "21282   104337   385110      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4a9b293-c601-4af8-ab62-b8cf3f11759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.loc[:,['pid', 'encoded_track_uri']]\n",
    "test_df = test_df.reset_index(drop=True).rename(columns={'encoded_track_uri': 'track_id'})\n",
    "test_DF = test_df.explode('track_id')\n",
    "test_DF = test_DF.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c57b6066-169a-4ed5-9f8e-da73b32327ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>118607</td>\n",
       "      <td>254495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>111806</td>\n",
       "      <td>349783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>103285</td>\n",
       "      <td>410110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>105762</td>\n",
       "      <td>454956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7333</th>\n",
       "      <td>109010</td>\n",
       "      <td>362276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid track_id\n",
       "6293  118607   254495\n",
       "926   111806   349783\n",
       "2693  103285   410110\n",
       "743   105762   454956\n",
       "7333  109010   362276"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_DF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0368f598-ddda-457d-ba12-ab591e1c9cfd",
   "metadata": {},
   "source": [
    "convert all the data into tensor format taht is compatible with tensorflow functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76cdbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train = np.array(train_DF['pid'], dtype=int)\n",
    "item_train = np.array(train_DF['track_id'], dtype=int)\n",
    "label_train = np.array(train_DF['label'], dtype=int)\n",
    "\n",
    "user_test = np.array(test_DF['pid'], dtype=int)\n",
    "item_test = np.array(test_DF['track_id'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c90787c3-0f5f-4eb6-b16a-69a9cb1c832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 13:23:10.032207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.042117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.043790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.046334: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 13:23:10.048111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.049768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.051357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.635950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.637766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.639329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 13:23:10.640787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13642 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"user_input\": user_train, \"item_input\": item_train}, label_train))\n",
    "# train_dataset = tf.random.shuffle(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e3555c2-70d1-44ce-805a-b8f7baca0e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = tf.convert_to_tensor(user_test, dtype=tf.int32)\n",
    "item_test = tf.convert_to_tensor(item_test, dtype=tf.int32)\n",
    "test_dataset = {\"user_input\": user_test, \"item_input\": item_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6787cfe4-09c8-4458-91ee-d35a934c5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024 #split into batches for computational parallerization \n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE) #convert the data to the format that is suitable for tensorflow GPU computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83911429-d6f3-4438-8a29-883b4f8a8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = train_df.shape[0]\n",
    "num_items = len(distinct_trackList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a16aa253",
   "metadata": {},
   "source": [
    "For the model architecture, please refer to figure 4 in our report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "173ee9d4-97c9-446d-ac8f-6456539aaf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, mf_dim=8, layers=[64, 32, 16, 8], reg_layers=[0, 0, 0, 0], reg_mf = 0): #by the default parameters are the same as official implementation\n",
    "    \n",
    "    assert len(layers) == len(reg_layers) #the dimension of layers and reg_layers must be the same \n",
    "    num_layer = len(layers) \n",
    "\n",
    "    user_input = tf.keras.Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = tf.keras.Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "    \n",
    "\n",
    "    MF_Embedding_User = tf.keras.layers.Embedding(input_dim = num_users, output_dim = mf_dim, name = 'mf_embedding_user',\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_mf), input_length=1)\n",
    "    MF_Embedding_Item = tf.keras.layers.Embedding(input_dim = num_items, output_dim = mf_dim, name = 'mf_embedding_item',\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_mf), input_length=1)   \n",
    "\n",
    "    MLP_Embedding_User = tf.keras.layers.Embedding(input_dim = num_users, output_dim = int(layers[0]/2), name = \"mlp_embedding_user\",\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_layers[0]), input_length=1)\n",
    "    MLP_Embedding_Item = tf.keras.layers.Embedding(input_dim = num_items, output_dim = int(layers[0]/2), name = 'mlp_embedding_item',\n",
    "                                  embeddings_initializer='normal', embeddings_regularizer = tf.keras.regularizers.l2(reg_layers[0]), input_length=1)   \n",
    "    \n",
    "    #matrix factorisation block\n",
    "    mf_user_latent = tf.keras.layers.Flatten()(MF_Embedding_User(user_input))\n",
    "    mf_item_latent = tf.keras.layers.Flatten()(MF_Embedding_Item(item_input))\n",
    "    mf_vector = tf.keras.layers.Multiply()([mf_user_latent, mf_item_latent]) # element-wise multiply \n",
    "\n",
    "    #multi layer perceptron block \n",
    "    mlp_user_latent = tf.keras.layers.Flatten()(MLP_Embedding_User(user_input))\n",
    "    mlp_item_latent = tf.keras.layers.Flatten()(MLP_Embedding_Item(item_input))\n",
    "    mlp_vector = tf.keras.layers.Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "    for idx in range(1, num_layer): #number of layers to be adjusted according to input of this function\n",
    "        layer = tf.keras.layers.Dense(layers[idx], kernel_regularizer= tf.keras.regularizers.l2(reg_layers[idx]), activation='relu', name=\"layer%d\" %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "        \n",
    "    #concatenation layer\n",
    "    predict_vector = tf.keras.layers.Concatenate()([mf_vector, mlp_vector])\n",
    "    \n",
    "    # output layer\n",
    "    prediction = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)\n",
    "    \n",
    "    #wrap model\n",
    "    model = tf.keras.Model(inputs=[user_input, item_input], \n",
    "                  outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec1e070a-beb7-445f-b503-0f34bc98b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = get_model(num_users, num_items)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy']) \n",
    "#classification task hence binary cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e1cd8f6-61d0-46ae-9ec5-ca07155fbffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_user (Embedding)  (None, 1, 32)        1057312     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlp_embedding_item (Embedding)  (None, 1, 32)        14624512    item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32)           0           mlp_embedding_user[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           mlp_embedding_item[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_user (Embedding)   (None, 1, 8)         264328      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mf_embedding_item (Embedding)   (None, 1, 8)         3656128     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 32)           2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8)            0           mf_embedding_user[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8)            0           mf_embedding_item[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 8)            0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16)           0           multiply[0][0]                   \n",
      "                                                                 layer3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            17          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 19,605,041\n",
      "Trainable params: 19,605,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5391aea0-fd31-4cc3-8ea1-af610f929b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 13:23:12.286881: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4486/4486 [==============================] - 46s 10ms/step - loss: 0.5127 - accuracy: 0.7261\n",
      "Epoch 2/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.4040 - accuracy: 0.8220\n",
      "Epoch 3/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3849 - accuracy: 0.8334\n",
      "Epoch 4/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3755 - accuracy: 0.8370\n",
      "Epoch 5/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3693 - accuracy: 0.8387\n",
      "Epoch 6/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3648 - accuracy: 0.8398\n",
      "Epoch 7/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3614 - accuracy: 0.8408\n",
      "Epoch 8/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3583 - accuracy: 0.8417\n",
      "Epoch 9/10\n",
      "4486/4486 [==============================] - 45s 10ms/step - loss: 0.3548 - accuracy: 0.8428\n",
      "Epoch 10/10\n",
      "4486/4486 [==============================] - 44s 10ms/step - loss: 0.3503 - accuracy: 0.8442\n",
      "CPU times: user 8min 21s, sys: 2min 5s, total: 10min 26s\n",
      "Wall time: 7min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(train_dataset, epochs=10, batch_size=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52b10cd9",
   "metadata": {},
   "source": [
    "test set is made of pairs of user and item. let the trained model predicts the probaility of each pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef042633-277a-4195-bb11-91b06aeb637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b1819e5-cab1-4744-8c51-8a4b6c56d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94685906],\n",
       "       [0.99082804],\n",
       "       [0.24004045],\n",
       "       ...,\n",
       "       [0.85735804],\n",
       "       [0.95772326],\n",
       "       [0.9794993 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
